{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Demographic Parity and Equalized Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook I created while reading [Equality of Opportunity in Supervised Learning](https://arxiv.org/abs/1610.02413). \n",
    "\n",
    "I am not sure there is a way to access the code the authors used to produce their plots/results, however, after some googling I found the [Fairlearn](https://fairlearn.github.io/v0.5.0/index.html#) package, which seemingly aims to _empowers developers of artificial intelligence (AI) systems to assess their system's fairness and mitigate any observed unfairness issues_. Reading their documentation they seem to implement, among others, the methodology described by the paper above.\n",
    "\n",
    "I thought it would be good to play around with this tool to assimilate the theoretical concepts introduced by the paper, so what you find below is a minimal overview of the practical use of this methodology, compared to another standard definition of fairness called _Demographic Parity_ (also implemented in Fairlearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      32650\n",
       "Female    16192\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fetch_openml(data_id=1590, as_frame=True)\n",
    "X = pd.get_dummies(data.data)\n",
    "y_true = (data.target == '>50K') * 1\n",
    "sex = data.data['sex']\n",
    "sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  workclass    fnlwgt     education  education-num      marital-status  \\\n",
       "0  25.0    Private  226802.0          11th            7.0       Never-married   \n",
       "1  38.0    Private   89814.0       HS-grad            9.0  Married-civ-spouse   \n",
       "2  28.0  Local-gov  336951.0    Assoc-acdm           12.0  Married-civ-spouse   \n",
       "3  44.0    Private  160323.0  Some-college           10.0  Married-civ-spouse   \n",
       "4  18.0        NaN  103497.0  Some-college           10.0       Never-married   \n",
       "\n",
       "          occupation relationship   race     sex  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male           0.0           0.0   \n",
       "1    Farming-fishing      Husband  White    Male           0.0           0.0   \n",
       "2    Protective-serv      Husband  White    Male           0.0           0.0   \n",
       "3  Machine-op-inspct      Husband  Black    Male        7688.0           0.0   \n",
       "4                NaN    Own-child  White  Female           0.0           0.0   \n",
       "\n",
       "   hours-per-week native-country  \n",
       "0            40.0  United-States  \n",
       "1            50.0  United-States  \n",
       "2            40.0  United-States  \n",
       "3            40.0  United-States  \n",
       "4            30.0  United-States  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import MetricFrame\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(min_samples_leaf=10, max_depth=4)\n",
    "classifier.fit(X, y_true)\n",
    "y_pred = classifier.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No fairness measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy score: 0.8443552680070431\n",
      "\n",
      "Accuracy score by: sex\n",
      "Female    0.925148\n",
      "Male      0.804288\n",
      "Name: accuracy_score, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gm = MetricFrame(accuracy_score, y_true, y_pred, sensitive_features=sex)\n",
    "print(f\"Total accuracy score: {gm.overall}\\n\")\n",
    "print(f\"Accuracy score by: {gm.by_group}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness metrics\n",
    "\n",
    "When working on fairness, before we can start _fairifying_ models we need to establish fairness metrics to optimise. Here we consider two definitions _Demographic Parity_ and _Equalized Odds_.\n",
    "\n",
    "* **Demographic Parity**: is defined as `Pr(Y_pred=1 | A=1) = Pr(Y_pred=1 | A=0)`\n",
    "* **Equalized Odds**: is defined as `Pr(Y_pred=1 | A=1, Y=y) = Pr(Y_pred=1 | A=0, Y=y)`\n",
    "\n",
    "Since in both cases we won't get perfect equality a good way to assess fairness is to look at the difference between the terms, and this is exactly what is done in `fairnlearn`:\n",
    "\n",
    "For _Demographic Parity_ we have:\n",
    "```\n",
    "demographic_parity_difference = |Pr(Y_pred=1 | A=1) - Pr(Y_pred=1 | A=0)|\n",
    "```\n",
    "\n",
    "For _Equalized Odds_ we have:\n",
    "```\n",
    "equalized_odds_difference = max(\n",
    "    |Pr(Y_pred=1 | A=1, Y=0) - Pr(Y_pred=1 | A=0, Y=0)|,\n",
    "    |Pr(Y_pred=1 | A=1, Y=1) - Pr(Y_pred=1 | A=0, Y=1)|\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic parity difference: 0.15004887369937472\n",
      "Equalized odds difference: 0.0811655575720911\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n",
    "\n",
    "dp_difference = demographic_parity_difference(y_true, y_pred, sensitive_features=sex)\n",
    "print(f\"Demographic parity difference: {dp_difference}\")\n",
    "\n",
    "eo_difference = equalized_odds_difference(y_true, y_pred, sensitive_features=sex)\n",
    "print(f\"Equalized odds difference: {eo_difference}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n",
    "\n",
    "mitigator = ExponentiatedGradient(classifier, DemographicParity())\n",
    "mitigator.fit(X, y_true, sensitive_features=sex)\n",
    "y_pred_mitigated = mitigator.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_dp = MetricFrame(accuracy_score, y_true, y_pred_mitigated, sensitive_features=sex)\n",
    "print(f\"Total accuracy score {gm_dp.overall}\")\n",
    "print(gm_dp.by_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_difference = demographic_parity_difference(y_true, y_pred_mitigated, sensitive_features=sex)\n",
    "print(f\"Demographic parity difference: {dp_difference}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalized Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from fairlearn.reductions import EqualizedOdds\n",
    "\n",
    "mitigator = ThresholdOptimizer(estimator=classifier, constraints='equalized_odds')\n",
    "mitigator.fit(X, y_true, sensitive_features=sex)\n",
    "y_pred_mitigated = mitigator.predict(X, sensitive_features=sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy score 0.8219155644731992\n",
      "sex\n",
      "Female    0.882102\n",
      "Male      0.792067\n",
      "Name: accuracy_score, dtype: object\n"
     ]
    }
   ],
   "source": [
    "gm_eo = MetricFrame(accuracy_score, y_true, y_pred_mitigated, sensitive_features=sex)\n",
    "print(f\"Total accuracy score {gm_eo.overall}\")\n",
    "print(gm_eo.by_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equalized odds difference: 0.0019057914241039087\n"
     ]
    }
   ],
   "source": [
    "eo_difference = equalized_odds_difference(y_true, y_pred_mitigated, sensitive_features=sex)\n",
    "print(f\"Equalized odds difference: {eo_difference}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
